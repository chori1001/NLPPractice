{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 김홍선 감독 작품 영화평 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.변신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr = 'https://movie.daum.net/moviedb/grade?movieId=126721&type=netizen&page={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "\n",
    "for n in range(50):\n",
    "    url = adr.format(n+1)\n",
    "    webpage = urlopen(url)\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    reviews = soup.findAll('p',{'class':'desc_review'})\n",
    "    for review in reviews:\n",
    "        review_list.append(review.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신_list=[]\n",
    "\n",
    "for line in review_list:\n",
    "    replace_line = line.replace(\"\\r\",\"\")\n",
    "    변신_list.append(replace_line)\n",
    "변신_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신_text = ' '\n",
    "for line in 변신_list:\n",
    "    변신_text = 변신_text + ''+str(line)\n",
    "변신_text_lines = 변신_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신_text_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신 = pd.DataFrame(변신_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.rename(columns={0:'평'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.isnull().values.any()\n",
    "변신.replace(\"\",float(\"NaN\"),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신['평'] = 변신['평'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.기술자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr2 = 'https://movie.daum.net/moviedb/grade?movieId=82891&type=netizen&page={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list2 = []\n",
    "\n",
    "for i in range(50):\n",
    "    url = adr2.format(i+1)\n",
    "    webpage = urlopen(url)\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    reviews = soup.findAll('p',{'class':'desc_review'})\n",
    "    for review in reviews:\n",
    "        review_list2.append(review.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들_list=[]\n",
    "\n",
    "for line in review_list:\n",
    "    replace_line = line.replace(\"\\r\",\"\")\n",
    "    replace_line = line.replace(\"\\n\",\"\")\n",
    "    기술자들_list.append(replace_line)\n",
    "기술자들_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들_text = ' '\n",
    "for line in 기술자들_list:\n",
    "    기술자들_text = 기술자들_text + ''+str(line)\n",
    "기술자들_text_lines = 기술자들_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들 = pd.DataFrame(기술자들_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들.rename(columns={0:'평'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들.replace(\"\",float(\"NaN\"), inplace = True)\n",
    "기술자들.isnull().values.any()\n",
    "기술자들.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(기술자들)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들['평'] = 기술자들['평'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 공모자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr3= 'https://movie.daum.net/moviedb/grade?movieId=65260&type=netizen&page={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list3 = []\n",
    "\n",
    "for i in range(50):\n",
    "    url = adr.format(i+1)\n",
    "    webpage = urlopen(url)\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    reviews = soup.findAll('p',{'class':'desc_review'})\n",
    "    for review in reviews:\n",
    "        review_list3.append(review.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들_list=[]\n",
    "\n",
    "for line in review_list:\n",
    "    replace_line = line.replace(\"\\r\",\"\")\n",
    "    replace_line = line.replace(\"\\n\",\"\")\n",
    "    공모자들_list.append(replace_line)\n",
    "공모자들_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들 = pd.DataFrame(공모자들_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.rename(columns={0:'평'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들['평'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.replace(\"\",float(\"NaN\"), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들['평'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들['평'].replace(\"\\n\",\"\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들['평'] = 공모자들['평'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변신, 기술자들, 공모자들 평 1~50 페이지 크롤링 후 데이터프레임 변환 완료."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불러올 땐 list라 데이터프레임으로 바꿔서 나름의 전처리를 하고 이를 다시 csv형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신.to_csv('변신.txt',header=None, encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들.to_csv('기술자들.txt',sep=\",\",header=None, encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.to_csv('공모자들.txt',header=None, encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF  \n",
    "나름 열심히 했으나 미완성...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 변환\n",
    "stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅈ ㅊ ㅋ ㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_matrix1 = tf_idf.fit_transform(변신[0])\n",
    "\n",
    "print(tf_idf_matrix1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cosine_sim = linear_kernel(tf_idf_matrix1, tf_idf_matrix1)\n",
    "\n",
    "# print(cosine_sim.shape)\n",
    "cosine_sim[0]\n",
    "# list(enumerate(cosine_sim[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 변환\n",
    "stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅈ ㅊ ㅋ ㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_matrix2 = tf_idf.fit_transform(기술자들['평'])\n",
    "\n",
    "print(tf_idf_matrix2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cosine_sim = linear_kernel(tf_idf_matrix2, tf_idf_matrix2)\n",
    "\n",
    "# print(cosine_sim.shape)\n",
    "cosine_sim[0]\n",
    "# list(enumerate(cosine_sim[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 변환\n",
    "stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅈ ㅊ ㅋ ㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_matrix3 = tf_idf.fit_transform(공모자들[0])\n",
    "\n",
    "print(tf_idf_matrix3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cosine_sim = linear_kernel(tf_idf_matrix3, tf_idf_matrix3)\n",
    "\n",
    "# print(cosine_sim.shape)\n",
    "cosine_sim[0]\n",
    "#list(enumerate(cosine_sim[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tagger = Mecab(dicpath=\"C:\\\\mecab\\\\mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅈ ㅊ ㅋ ㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')\n",
    "# stop_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신단어 = []\n",
    "for post in 변신[0]:\n",
    "    for noun in tagger.nouns(post):\n",
    "        if noun not in stop_words:\n",
    "            변신단어.append(noun)\n",
    "\n",
    "변신단어[0:10]\n",
    "\n",
    "from collections import Counter\n",
    "num_top_nouns = 15\n",
    "변신단어_counter = Counter(변신단어)\n",
    "변신단어탑 = dict(변신단어_counter.most_common(num_top_nouns))\n",
    "변신단어탑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자단어 = []\n",
    "for post in 기술자들[0]:\n",
    "    for noun in tagger.nouns(post):\n",
    "        if noun not in stop_words:\n",
    "            기술자단어.append(noun)\n",
    "\n",
    "기술자단어[0:10]\n",
    "\n",
    "from collections import Counter\n",
    "num_top_nouns = 15\n",
    "기술자단어_counter = Counter(기술자단어)\n",
    "기술자단어탑 = dict(기술자단어_counter.most_common(num_top_nouns))\n",
    "기술자단어탑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자단어 = []\n",
    "for post in 공모자들[0]:\n",
    "    for noun in tagger.nouns(post):\n",
    "        if noun not in stop_words:\n",
    "            공모자단어.append(noun)\n",
    "\n",
    "공모자단어[0:10]\n",
    "\n",
    "from collections import Counter\n",
    "num_top_nouns = 15\n",
    "공모자단어_counter = Counter(공모자단어)\n",
    "공모자단어탑 = dict(공모자단어_counter.most_common(num_top_nouns))\n",
    "공모자단어탑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pytagcloud\n",
    "import webbrowser\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "변신_wc = WordCloud(background_color=\"white\", font_path='c:/Windows/fonts/malgun.ttf')\n",
    "변신_wc.generate_from_frequencies(변신단어탑)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure()\n",
    "figure.set_size_inches(20, 20)\n",
    "ax = figure.add_subplot(1, 1, 1)\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(변신_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "기술자들_wc = WordCloud(background_color=\"white\", font_path='c:/Windows/fonts/malgun.ttf')\n",
    "기술자들_wc.generate_from_frequencies(기술자단어탑)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure()\n",
    "figure.set_size_inches(20, 20)\n",
    "ax = figure.add_subplot(1, 1, 1)\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(기술자들_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "공모자들_wc = WordCloud(background_color=\"white\", font_path='c:/Windows/fonts/malgun.ttf')\n",
    "공모자들_wc.generate_from_frequencies(공모자단어탑)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure()\n",
    "figure.set_size_inches(20, 20)\n",
    "ax = figure.add_subplot(1, 1, 1)\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(공모자들_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정제하던 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅇㅇㅈ ㅊ ㅋ ㅋㅋㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신[0] = 변신[0].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "변신정제 = []\n",
    "for sentence in 변신[0]:\n",
    "    temp_X = okt.morphs(sentence, stem=True) \n",
    "    temp_X = [word for word in temp_X if not word in stop_words] \n",
    "    변신정제.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들[0] = 공모자들[0].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "공모자정제 = []\n",
    "for sentence in 공모자들[0]:\n",
    "    temp_X = okt.morphs(sentence, stem=True) \n",
    "    temp_X = [word for word in temp_X if not word in stop_words] \n",
    "    공모자정제.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자들[0] = 기술자들[0].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "기술자정제 = []\n",
    "for sentence in 기술자들[0]:\n",
    "    temp_X = okt.morphs(sentence, stem=True) \n",
    "    temp_X = [word for word in temp_X if not word in stop_words] \n",
    "    기술자정제.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "기술자정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자정제[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(공모자정제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합치자 = []\n",
    "\n",
    "for i in range(0,len(공모자정제)):\n",
    "    for a in range(0,len(공모자정제[i])):\n",
    "        공모자합치자.append(공모자정제[i][a])\n",
    "    print(공모자합치자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합치자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합 = pd.DataFrame(공모자합치자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.rename(columns = {0:'평'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF로 벡터화\n",
    "# 1글자도 인식이 되도록 토큰 패턴 변경\n",
    "tf_idf = TfidfVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "tf_idf.fit(공모자단어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_idf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.transform(공모자합치자).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자들.drop(['key'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "변신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합.rename(columns={'평':'응'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(공모자합.index, index=공모자합['응']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices['임창정']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similar(응, indices, cosine_sim):\n",
    "\n",
    "   \n",
    "    try:\n",
    "        index = indices[응]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # 해당 영화의 유사도를 배열로 변환\n",
    "    # 0 : 인덱스, 1 : 유사도\n",
    "    scores = list(enumerate(cosine_sim[index]))\n",
    "\n",
    "    # 유사도(x[1] 항목)를 기준으로 높은 순으로 정렬\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사도가 높은 자신을 제외하고 5개를 추출\n",
    "    scores = scores[1:2]\n",
    "    #print(scores)\n",
    "    # 인덱스를 구함\n",
    "    indices = [x[0] for x in scores]\n",
    "    #print(indices)\n",
    "    # 각 인덱스의 영화 제목을 구함\n",
    "    titles = 공모자합['응'].iloc[indices] \n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "공모자합['응'][[3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 변환\n",
    "\n",
    "stop_words=stop_words = \"ㄱ ㄴ ㄷ ㄹ ㅁ ㅂ ㅅ ㅇ ㅈ ㅊ ㅋ ㅌ ㅍ ㅎ ㄲ ㄸ ㅆ ㄲ ㅉ 은 이 것 등 더 를 좀 즉 인 옹 때 만 원 이때 개 일 기 시 럭 갤 성 삼 스 폰 트 드 기 이 리 폴 사 전 마 자 플 블 가 ㅋ ㅎ ㅠ ㅜ\"\n",
    "stop_words=stop_words.split(' ')\n",
    "\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_matrix = tf_idf.fit_transform(공모자정제)\n",
    "\n",
    "# 데이터의 개수 : 10000\n",
    "# 단어의 개수 : 32350\n",
    "print(tf_idf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# 10000 x 10000을 서로 내적하여 코사인 유사도를 구함\n",
    "# 각 항목은 두 영화의 유사도를 나타냄\n",
    "cosine_sim = linear_kernel(tf_idf_matrix, tf_idf_matrix)\n",
    "\n",
    "# print(cosine_sim.shape)\n",
    "cosine_sim[0]\n",
    "# list(enumerate(cosine_sim[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar('나름', indices, cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
